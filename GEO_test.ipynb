{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3d78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import tempfile\n",
    "import os\n",
    "import tarfile\n",
    "import scanpy as sc\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b607530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Claude API key from local text file\n",
    "# check if we're on MacOS or Windows and read appropriate file\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    with open(\"C:/Users/David/.claude_api.txt\") as f:\n",
    "        claude_key = f.read().strip()\n",
    "else:\n",
    "    with open(\"/Users/tatarakis/.api-keys/tatarakis-test-key.txt\") as f:\n",
    "        claude_key = f.read().strip()\n",
    "\n",
    "os.environ['ANTHROPIC_API_KEY'] = claude_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd78657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatarakis/langchain_agent_test/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"claude-sonnet-4-5-20250929\",\n",
    "    timeout=120,\n",
    "    max_tokens=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16957258",
   "metadata": {},
   "source": [
    "# Initial Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aead36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='92ec6e34-9fd8-4277-9034-a1a8fe05af4b'),\n",
       "  AIMessage(content=[{'id': 'toolu_012gSyNivdQdzeTWJ73PdfX9', 'input': {'city': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Euj9uQNxmUwB23At5CwYCy', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 569, 'output_tokens': 54, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--019b9498-2542-7c60-976f-f6c0f24f2b7c-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'toolu_012gSyNivdQdzeTWJ73PdfX9', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 569, 'output_tokens': 54, 'total_tokens': 623, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='67bf662a-85c4-40ee-b467-58abff8ae72b', tool_call_id='toolu_012gSyNivdQdzeTWJ73PdfX9'),\n",
       "  AIMessage(content=\"According to the weather information, it's always sunny in San Francisco!\", additional_kwargs={}, response_metadata={'id': 'msg_01X5tMKvSFpADr4YmKtpwmTg', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 643, 'output_tokens': 17, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, id='lc_run--019b9498-352e-7a30-86da-509711c6e252-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 643, 'output_tokens': 17, 'total_tokens': 660, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cb253",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "We need to define the set of tools the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4fe0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "################\n",
    "# HELPER TOOLS #\n",
    "################\n",
    "\n",
    "# These functions are not called by the agent directly, but are used internally by other tools.\n",
    "def get_geo_ftp_path(accession: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the FTP directory for a GEO accession (GSE or GSM).\n",
    "    \"\"\"\n",
    "    prefix = accession[:3]     # GSE or GSM\n",
    "    number = accession[3:]\n",
    "    chunk = prefix + number[:-3] + \"nnn\"\n",
    "\n",
    "    if prefix == \"GSE\":\n",
    "        return f\"/geo/series/{chunk}/{accession}/suppl/\"\n",
    "    elif prefix == \"GSM\":\n",
    "        return f\"/geo/samples/{chunk}/{accession}/suppl/\"\n",
    "    else:\n",
    "        raise ValueError(\"Only GSE or GSM supported\")\n",
    "\n",
    "def list_tar_contents_helper(file_name: str):\n",
    "    \"\"\"List contents of a tar file.\"\"\"\n",
    "    contents = []\n",
    "    with tarfile.open(file_name, \"r:*\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            contents.append(member.name)\n",
    "    return contents\n",
    "\n",
    "def unpack_tar_file_helper(tar_file_path: str, output_dir: str):\n",
    "    \"\"\"Unpack a tar file to a specified directory.\"\"\"\n",
    "    with tarfile.open(tar_file_path, \"r:*\") as tar:\n",
    "        tar.extractall(path=output_dir)\n",
    "        return [member.name for member in tar.getmembers()]\n",
    "\n",
    "#########\n",
    "# TOOLS #\n",
    "#########\n",
    "\n",
    "# These are the functions that the agent can call.\n",
    "@tool\n",
    "def list_geo_files(accession: str) -> list:\n",
    "    \"\"\"\n",
    "    List supplementary files for a GEO accession (GSE or GSM).\n",
    "    Returns a list of available files.\n",
    "    \"\"\"\n",
    "    ftp = FTP(\"ftp.ncbi.nlm.nih.gov\")\n",
    "    ftp.login()\n",
    "\n",
    "    path = get_geo_ftp_path(accession)\n",
    "    try:\n",
    "        ftp.cwd(path)\n",
    "    except:\n",
    "        try:\n",
    "            path = re.sub(r\"suppl/$\", \"\", path)\n",
    "            ftp.cwd(path)\n",
    "            warnings.warn(f\"No supplementary files for: {accession}\")\n",
    "        except:\n",
    "            ftp.quit()\n",
    "            raise FileNotFoundError(f\"Could not find FTP path: {path}\")\n",
    "\n",
    "    files = ftp.nlst()\n",
    "    ftp.quit()\n",
    "    return files\n",
    "\n",
    "\n",
    "@tool\n",
    "def download_geo_supp_file(accession: str, file_name: str, output_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a supplementary file for a GEO accession (GSE or GSM).\n",
    "    Creates the output directory if it doesn't exist.\n",
    "    Returns the path to the downloaded file.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    ftp = FTP(\"ftp.ncbi.nlm.nih.gov\")\n",
    "    ftp.login()\n",
    "    \n",
    "    path = get_geo_ftp_path(accession)\n",
    "    try:\n",
    "        ftp.cwd(path)\n",
    "    except:\n",
    "        try:\n",
    "            path = re.sub(r\"suppl/$\", \"\", path)\n",
    "            ftp.cwd(path)\n",
    "            warnings.warn(f\"No supplementary files for: {accession}\")\n",
    "        except:\n",
    "            ftp.quit()\n",
    "            raise FileNotFoundError(f\"Could not find FTP path: {path}\")\n",
    "\n",
    "    local_file_path = os.path.join(output_dir, file_name)\n",
    "    with open(local_file_path, \"wb\") as f:\n",
    "        try:\n",
    "            ftp.retrbinary(f\"RETR {file_name}\", f.write)\n",
    "        except Exception as e:\n",
    "            ftp.quit()\n",
    "            raise e\n",
    "    ftp.quit()\n",
    "    \n",
    "    print(f\"Downloaded: {local_file_path}\")\n",
    "    return local_file_path\n",
    "\n",
    "# Let's the agent list any directory it needs to.\n",
    "@tool\n",
    "def list_directory(directory: str) -> list:\n",
    "    \"\"\"\n",
    "    List all files and folders in a directory.\n",
    "    \"\"\"\n",
    "    return os.listdir(directory)\n",
    "\n",
    "# This tool lists contents of all tar files in a directory.\n",
    "@tool\n",
    "def batch_list_tar_contents(directory: str) -> dict:\n",
    "    \"\"\"\n",
    "    List contents of all tar files in a directory.\n",
    "    Returns a dict mapping tar filenames to their contents.\n",
    "    \"\"\"\n",
    "    tar_contents = {}\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".tar\") or file.endswith(\".tar.gz\") or file.endswith(\".tgz\"):\n",
    "            tar_file_path = os.path.join(directory, file)\n",
    "            contents = list_tar_contents_helper(tar_file_path)\n",
    "            tar_contents[file] = contents\n",
    "    return tar_contents\n",
    "\n",
    "# This tool unpacks all tar files in a directory.\n",
    "@tool\n",
    "def batch_unpack_tar_files(directory: str) -> list:\n",
    "    \"\"\"\n",
    "    Unpack all tar files in a directory.\n",
    "    Returns list of unpacked file names.\n",
    "    \"\"\"\n",
    "    unpacked_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".tar\") or file.endswith(\".tar.gz\") or file.endswith(\".tgz\"):\n",
    "            tar_file_path = os.path.join(directory, file)\n",
    "            unpacked = unpack_tar_file_helper(tar_file_path, directory)\n",
    "            unpacked_files.extend(unpacked)\n",
    "            print(f\"Unpacked {file}: {len(unpacked)} files\")\n",
    "    return unpacked_files\n",
    "\n",
    "# This tool renames files in a directory according to 10x Genomics conventions.\n",
    "@tool\n",
    "def rename_geo_files(directory: str) -> dict:\n",
    "    \"\"\"\n",
    "    Rename files in a directory according to 10x Genomics conventions.\n",
    "    Returns the rename mapping.\n",
    "    \"\"\"\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    matrix = None\n",
    "    features = None\n",
    "    barcodes = None\n",
    "\n",
    "    for f in files:\n",
    "        n = f.lower()\n",
    "        # Matrix file\n",
    "        if \"mtx\" in n:\n",
    "            matrix = f\n",
    "            continue\n",
    "        # Features file\n",
    "        if any(x in n for x in [\"gene\", \"feature\", \"symbol\"]):\n",
    "            features = f\n",
    "            continue\n",
    "        # Barcodes file\n",
    "        if any(x in n for x in [\"barcode\", \"cell\"]):\n",
    "            barcodes = f\n",
    "            continue\n",
    "\n",
    "    if not (matrix and features and barcodes):\n",
    "        raise ValueError(\n",
    "            f\"Could not find all required files in {directory}. \"\n",
    "            f\"Found matrix={matrix}, features={features}, barcodes={barcodes}\"\n",
    "        )\n",
    "\n",
    "    rename_map = {\n",
    "        matrix: \"matrix.mtx\",\n",
    "        features: \"features.tsv\",\n",
    "        barcodes: \"barcodes.tsv\"\n",
    "    }\n",
    "\n",
    "    for key, value in list(rename_map.items()):\n",
    "        if key.endswith(\".gz\"):\n",
    "            rename_map[key] = value + \".gz\"\n",
    "\n",
    "    for old, new in rename_map.items():\n",
    "        src = os.path.join(directory, old)\n",
    "        dst = os.path.join(directory, new)\n",
    "        shutil.move(src, dst)\n",
    "        print(f\"Renamed {old} → {new}\")\n",
    "\n",
    "    return rename_map\n",
    "\n",
    "# This tool structures a directory to conform to 10x Genomics file organization.\n",
    "@tool\n",
    "def structure_10x_directory(directory: str) -> str:\n",
    "    \"\"\"\n",
    "    Structure a directory to conform to 10x Genomics file organization.\n",
    "    Creates a '10x_counts' subdirectory and moves relevant files there.\n",
    "    Returns the path to the 10x_counts directory.\n",
    "    \"\"\"\n",
    "    counts_directory = os.path.join(directory, \"10x_counts\")\n",
    "    os.makedirs(counts_directory, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file in [\"matrix.mtx\", \"matrix.mtx.gz\", \"features.tsv\", \"features.tsv.gz\", \"barcodes.tsv\", \"barcodes.tsv.gz\"]:\n",
    "            src = os.path.join(directory, file)\n",
    "            dst = os.path.join(counts_directory, file)\n",
    "            shutil.move(src, dst)\n",
    "            print(f\"Moved {file} to 10x_counts/\")\n",
    "    \n",
    "    return counts_directory\n",
    "\n",
    "# This tool converts CSV files to TSV files (which scanpy expects).\n",
    "@tool\n",
    "def convert_csv_to_tsv(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert CSV files to TSV files, handling both uncompressed and gzipped files.\n",
    "    Returns the path to the TSV file.\n",
    "    \"\"\"\n",
    "    if file_path.endswith(\".csv\"):\n",
    "        tsv_file_path = file_path[:-4] + \".tsv\"\n",
    "        with open(file_path, \"r\") as csv_file, open(tsv_file_path, \"w\") as tsv_file:\n",
    "            for line in csv_file:\n",
    "                tsv_file.write(line.replace(\",\", \"\\t\"))\n",
    "        return tsv_file_path\n",
    "\n",
    "    if file_path.endswith(\".csv.gz\"):\n",
    "        tsv_file_path = file_path[:-7] + \".tsv.gz\"\n",
    "        with gzip.open(file_path, \"rt\") as csv_file, gzip.open(tsv_file_path, \"wt\") as tsv_file:\n",
    "            for line in csv_file:\n",
    "                tsv_file.write(line.replace(\",\", \"\\t\"))\n",
    "        return tsv_file_path\n",
    "\n",
    "    return file_path\n",
    "\n",
    "# Gets the dimensions of a sparse matrix from a Matrix Market file.\n",
    "@tool\n",
    "def get_matrix_dimensions(matrix_file_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Get the dimensions of a sparse matrix from a Matrix Market file.\n",
    "    Returns (rows, cols, nnz).\n",
    "    \"\"\"\n",
    "    opener = gzip.open if matrix_file_path.endswith(\".gz\") else open\n",
    "\n",
    "    with opener(matrix_file_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"%\") or line.startswith(\"%%\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 3:\n",
    "                rows, cols, nnz = map(int, parts)\n",
    "                return rows, cols, nnz\n",
    "    raise ValueError(\"Could not determine matrix dimensions from file.\")\n",
    "\n",
    "# This tool checks and reformats features file to conform to 10x Genomics conventions.\n",
    "@tool\n",
    "def format_features_file(features_file_path: str, matrix_dimensions: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Check and reformat features file to conform to 10x Genomics conventions.\n",
    "    Returns the path to the reformatted file.\n",
    "    \"\"\"\n",
    "    if features_file_path.endswith(\".gz\"):\n",
    "        with gzip.open(features_file_path, \"rt\") as f:\n",
    "            lines = f.readlines()\n",
    "    else:\n",
    "        with open(features_file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "    \n",
    "    nrows = len(lines)\n",
    "    has_header = (nrows == matrix_dimensions[0] + 1)\n",
    "    \n",
    "    if has_header:\n",
    "        rows = [line.strip().split(\"\\t\") for line in lines[1:]]\n",
    "    else:\n",
    "        rows = [line.strip().split(\"\\t\") for line in lines]\n",
    "\n",
    "    features_df = pd.DataFrame(rows)\n",
    "    if features_df.shape[1] == 1:\n",
    "        features_df[1] = features_df.iloc[:, 0]\n",
    "        features_df[2] = \"gene\"\n",
    "    elif features_df.shape[1] == 2:\n",
    "        features_df[2] = \"gene\"\n",
    "    features_df = features_df.iloc[:, :3]\n",
    "    \n",
    "    if features_file_path.endswith(\".gz\"):\n",
    "        with gzip.open(features_file_path, \"wt\") as f:\n",
    "            features_df.to_csv(f, sep=\"\\t\", index=False, header=False)\n",
    "    else:\n",
    "        with open(features_file_path, \"w\") as f:\n",
    "            features_df.to_csv(f, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    return features_file_path\n",
    "\n",
    "# This tool checks and reformats barcodes file to conform to 10x Genomics conventions.\n",
    "@tool\n",
    "def format_barcodes_file(barcodes_file_path: str, matrix_dimensions: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Check and reformat barcodes file to conform to 10x Genomics conventions.\n",
    "    Returns the path to the reformatted file.\n",
    "    \"\"\"\n",
    "    if barcodes_file_path.endswith(\".gz\"):\n",
    "        with gzip.open(barcodes_file_path, \"rt\") as f:\n",
    "            lines = f.readlines()\n",
    "    else:\n",
    "        with open(barcodes_file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "    \n",
    "    nrows = len(lines)\n",
    "    has_header = (nrows == matrix_dimensions[1] + 1)\n",
    "    \n",
    "    if has_header:\n",
    "        rows = [line.strip().split(\"\\t\") for line in lines[1:]]\n",
    "    else:\n",
    "        rows = [line.strip().split(\"\\t\") for line in lines]\n",
    "\n",
    "    barcodes_df = pd.DataFrame(rows)\n",
    "    barcodes_df = barcodes_df.iloc[:, :1]\n",
    "    \n",
    "    tenx_pattern = r\"([ACGTN]{16,20}-\\d+)\"\n",
    "    barcodes_df[barcodes_df.columns[0]] = barcodes_df[barcodes_df.columns[0]].str.extract(tenx_pattern)\n",
    "\n",
    "    if barcodes_file_path.endswith(\".gz\"):\n",
    "        with gzip.open(barcodes_file_path, \"wt\") as f:\n",
    "            barcodes_df.to_csv(f, sep=\"\\t\", index=False, header=False)\n",
    "    else:\n",
    "        with open(barcodes_file_path, \"w\") as f:\n",
    "            barcodes_df.to_csv(f, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    return barcodes_file_path\n",
    "\n",
    "# This tool builds an anndata object from 10x formatted counts matrix.\n",
    "@tool\n",
    "def build_anndata(counts_directory: str, sample_name: str, output_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Build an anndata object from 10x formatted counts matrix.\n",
    "    Saves to output_dir/adatas/sample_name.h5ad.\n",
    "    Returns the path to the saved file.\n",
    "    \"\"\"\n",
    "    adata = sc.read_10x_mtx(counts_directory)\n",
    "    adata.obs[\"sample_name\"] = sample_name\n",
    "    \n",
    "    adata_dir = os.path.join(output_dir, \"adatas\")\n",
    "    os.makedirs(adata_dir, exist_ok=True)\n",
    "    \n",
    "    saved_file_path = os.path.join(adata_dir, f\"{sample_name}.h5ad\")\n",
    "    adata.write_h5ad(saved_file_path)\n",
    "\n",
    "    if os.path.exists(saved_file_path):\n",
    "        print(f\"AnnData object successfully saved at: {saved_file_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Failed to save AnnData object at: {saved_file_path}\")\n",
    "    \n",
    "    return saved_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a82b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        list_geo_files,\n",
    "        download_geo_supp_file,\n",
    "        list_directory,\n",
    "        batch_list_tar_contents,\n",
    "        batch_unpack_tar_files,\n",
    "        rename_geo_files,\n",
    "        structure_10x_directory,\n",
    "        convert_csv_to_tsv,\n",
    "        get_matrix_dimensions,\n",
    "        format_features_file,\n",
    "        format_barcodes_file,\n",
    "        build_anndata\n",
    "    ],\n",
    "    system_prompt=\"\"\"You are a helpful assistant specialized in processing GEO single-cell RNA-seq datasets.\n",
    "\n",
    "When processing a GEO dataset:\n",
    "1. List available files with list_geo_files\n",
    "2. Download relevant files using download_geo_supp_file (creates directories automatically)\n",
    "3. Use list_directory to see what was downloaded\n",
    "4. Extract tar archives with batch_unpack_tar_files\n",
    "5. Use list_directory to examine extracted files\n",
    "6. Rename files to 10x conventions with rename_geo_files\n",
    "7. Convert CSV to TSV if needed\n",
    "8. Structure the directory with structure_10x_directory\n",
    "9. Check matrix dimensions and fix features/barcodes if needed\n",
    "10. Build the AnnData object with build_anndata\n",
    "\n",
    "Always use the paths returned by tools in subsequent tool calls.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43acf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = agent.invoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"\"\"Tell me what you are designed to do and what you need.\"\"\"\n",
    "    }]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aabe120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a specialized assistant designed to process GEO (Gene Expression Omnibus) single-cell RNA-seq datasets and convert them into AnnData objects that can be used for downstream analysis.\n",
      "\n",
      "## What I can do:\n",
      "\n",
      "1. **Download GEO data**: Retrieve supplementary files from GEO accessions (GSE or GSM)\n",
      "2. **Extract archives**: Unpack tar files to access the data\n",
      "3. **File management**: List, rename, and organize files according to 10x Genomics conventions\n",
      "4. **Format conversion**: Convert CSV files to TSV format when needed\n",
      "5. **Data validation**: Check matrix dimensions and ensure features/barcodes files are properly formatted\n",
      "6. **Build AnnData objects**: Create standardized .h5ad files from count matrices\n",
      "\n",
      "## What I need from you:\n",
      "\n",
      "To process a dataset, I need:\n",
      "\n",
      "- **GEO Accession ID** (e.g., GSE123456) - the dataset you want to process\n",
      "- **Output directory** (optional) - where you want the processed data saved (I can use a default if not specified)\n",
      "- **Sample name** (optional for some steps) - what to name the final AnnData object\n",
      "\n",
      "## My typical workflow:\n",
      "\n",
      "1. List available files for your GEO accession\n",
      "2. Download the relevant supplementary files\n",
      "3. Extract any compressed archives\n",
      "4. Rename files to match 10x Genomics naming conventions (matrix.mtx, features.tsv, barcodes.tsv)\n",
      "5. Structure the directory properly\n",
      "6. Validate and format the matrix components\n",
      "7. Build the final AnnData object (.h5ad file)\n",
      "\n",
      "**Just provide me with a GEO accession ID and I'll get started!** For example: \"Process GSE123456\" or \"Download and build AnnData for GSE123456\"\n"
     ]
    }
   ],
   "source": [
    "print(test[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400cac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: /Users/tatarakis/data/langchain_geo_test_data/GSE209912_barcodes.csv.gz\n",
      "Downloaded: /Users/tatarakis/data/langchain_geo_test_data/GSE209912_symbols.csv.gz\n",
      "Downloaded: /Users/tatarakis/data/langchain_geo_test_data/GSE209912_counts.mtx.gz\n",
      "Renamed GSE209912_counts.mtx.gz → matrix.mtx.gz\n",
      "Renamed GSE209912_symbols.tsv.gz → features.tsv.gz\n",
      "Renamed GSE209912_barcodes.csv.gz → barcodes.tsv.gz\n",
      "Moved features.tsv.gz to 10x_counts/\n",
      "Moved barcodes.tsv.gz to 10x_counts/\n",
      "Moved matrix.mtx.gz to 10x_counts/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatarakis/langchain_agent_test/.venv/lib/python3.14/site-packages/anndata/_core/anndata.py:1806: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object successfully saved at: /Users/tatarakis/data/langchain_geo_test_data/adatas/GSE209912.h5ad\n"
     ]
    }
   ],
   "source": [
    "# Set working directory for the agent to use\n",
    "WORKING_DIR = \"/Users/tatarakis/data/langchain_geo_test_data\"\n",
    "\n",
    "# Run the agent. Pass the working directory in the prompt\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": f\"\"\"Download counts data for GSE209912, extract the 10x Genomics counts matrix, \n",
    "reformat it as needed, and build an AnnData object from it.\n",
    "\n",
    "Use {WORKING_DIR} as the base directory for all file operations.\"\"\"\n",
    "    }]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914a4b3",
   "metadata": {},
   "source": [
    "# Batch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddd9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accessions = [\n",
    "    \"GSE174188\",\n",
    "    \"GSE209912\",\n",
    "    \"GSE188367\",\n",
    "    \"GSE136103\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ae2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: list_geo_files\n",
      "  Args: {'accession': 'GSE188367'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"GSE188367_atac_tf_counts.tar.gz\", \"filelist.txt\", \"GSE188367_RAW.tar\"]...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: download_geo_supp_file\n",
      "  Args: {'accession': 'GSE188367', 'file_name': 'GSE188367_RAW.tar', 'output_dir': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "  Tool: download_geo_supp_file\n",
      "  Args: {'accession': 'GSE188367', 'file_name': 'GSE188367_atac_tf_counts.tar.gz', 'output_dir': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "Downloaded: /Users/tatarakis/data/langchain_geo_test_data/GSE188367_atac_tf_counts.tar.gz\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: /Users/tatarakis/data/langchain_geo_test_data/GSE188367_atac_tf_counts.tar.gz...\n",
      "Downloaded: /Users/tatarakis/data/langchain_geo_test_data/GSE188367_RAW.tar\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: /Users/tatarakis/data/langchain_geo_test_data/GSE188367_RAW.tar...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: list_directory\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "  Tool: batch_list_tar_contents\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\".DS_Store\", \"GSE188367_RAW.tar\", \"GSE188367_atac_tf_counts.tar.gz\"]...\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: {\"GSE188367_RAW.tar\": [\"GSM5678317_BM-Old4_counts.tar.gz\", \"GSM5678318_BM-Old5_counts.tar.gz\", \"GSM5678319_BM-UPN01_counts.tar.gz\", \"GSM5678320_BM-UPN02_counts.tar.gz\", \"GSM5678321_BM-UPN03_counts.tar.gz\", \"GSM5678322_BM-UPN04_counts.tar.gz\", \"GSM5678323_BM-UPN06_counts.tar.gz\", \"GSM5678324_BM-UPN11_counts.tar.gz\", \"GSM5678325_BM-UPN12_counts.tar.gz\", \"GSM5678326_CD34-Old4_counts.tar.gz\", \"GSM5678327_CD34-Old5_counts.tar.gz\", \"GSM5678328_CD34-UPN01_counts.tar.gz\", \"GSM5678329_CD34-UPN02_counts.t...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: batch_unpack_tar_files\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "Unpacked GSE188367_RAW.tar: 24 files\n",
      "Unpacked GSE188367_atac_tf_counts.tar.gz: 4 files\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"GSM5678317_BM-Old4_counts.tar.gz\", \"GSM5678318_BM-Old5_counts.tar.gz\", \"GSM5678319_BM-UPN01_counts.tar.gz\", \"GSM5678320_BM-UPN02_counts.tar.gz\", \"GSM5678321_BM-UPN03_counts.tar.gz\", \"GSM5678322_BM-UPN04_counts.tar.gz\", \"GSM5678323_BM-UPN06_counts.tar.gz\", \"GSM5678324_BM-UPN11_counts.tar.gz\", \"GSM5678325_BM-UPN12_counts.tar.gz\", \"GSM5678326_CD34-Old4_counts.tar.gz\", \"GSM5678327_CD34-Old5_counts.tar.gz\", \"GSM5678328_CD34-UPN01_counts.tar.gz\", \"GSM5678329_CD34-UPN02_counts.tar.gz\", \"GSM5678330_CD...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: list_directory\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"GSM5678330_CD34-UPN03_counts.tar.gz\", \"GSM5678328_CD34-UPN01_counts.tar.gz\", \"GSM5678321_BM-UPN03_counts.tar.gz\", \".DS_Store\", \"GSM5678340_HRI10_counts.tar.gz\", \"GSM5678318_BM-Old5_counts.tar.gz\", \"GSM5678322_BM-UPN04_counts.tar.gz\", \"GSM5678332_CD34-UPN06_counts.tar.gz\", \"GSM5678317_BM-Old4_counts.tar.gz\", \"GSM5678331_CD34-UPN04_counts.tar.gz\", \"GSM5678333_CD34-UPN11_counts.tar.gz\", \"GSM5678339_HRI08_counts.tar.gz\", \"GSM5678336_CTR08_counts.tar.gz\", \"GSM5678329_CD34-UPN02_counts.tar.gz\", \"GSM...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: batch_unpack_tar_files\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "Unpacked GSM5678330_CD34-UPN03_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678328_CD34-UPN01_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678321_BM-UPN03_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678340_HRI10_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678318_BM-Old5_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678322_BM-UPN04_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678332_CD34-UPN06_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678317_BM-Old4_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678331_CD34-UPN04_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678333_CD34-UPN11_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678339_HRI08_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678336_CTR08_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678329_CD34-UPN02_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678326_CD34-Old4_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678323_BM-UPN06_counts.tar.gz: 4 files\n",
      "Unpacked GSE188367_RAW.tar: 24 files\n",
      "Unpacked GSM5678324_BM-UPN11_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678320_BM-UPN02_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678319_BM-UPN01_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678335_CTR07_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678334_CD34-UPN12_counts.tar.gz: 4 files\n",
      "Unpacked GSE188367_atac_tf_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678325_BM-UPN12_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678327_CD34-Old5_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678338_HRI07_counts.tar.gz: 4 files\n",
      "Unpacked GSM5678337_CTR10_counts.tar.gz: 4 files\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"CD34-UPN03_counts\", \"CD34-UPN03_counts/barcodes.tsv.gz\", \"CD34-UPN03_counts/matrix.mtx.gz\", \"CD34-UPN03_counts/features.tsv.gz\", \"CD34-UPN01_counts\", \"CD34-UPN01_counts/barcodes.tsv.gz\", \"CD34-UPN01_counts/matrix.mtx.gz\", \"CD34-UPN01_counts/features.tsv.gz\", \"BM-UPN03_counts\", \"BM-UPN03_counts/barcodes.tsv.gz\", \"BM-UPN03_counts/matrix.mtx.gz\", \"BM-UPN03_counts/features.tsv.gz\", \"HRI10_counts\", \"HRI10_counts/barcodes.tsv.gz\", \"HRI10_counts/matrix.mtx.gz\", \"HRI10_counts/features.tsv.gz\", \"BM-Old...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: list_directory\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"GSM5678330_CD34-UPN03_counts.tar.gz\", \"CD34-UPN03_counts\", \"CD34-Old4_counts\", \"CD34-UPN11_counts\", \"GSM5678328_CD34-UPN01_counts.tar.gz\", \"GSM5678321_BM-UPN03_counts.tar.gz\", \".DS_Store\", \"GSM5678340_HRI10_counts.tar.gz\", \"GSM5678318_BM-Old5_counts.tar.gz\", \"CD34-UPN01_counts\", \"GSM5678322_BM-UPN04_counts.tar.gz\", \"GSM5678332_CD34-UPN06_counts.tar.gz\", \"GSM5678317_BM-Old4_counts.tar.gz\", \"GSM5678331_CD34-UPN04_counts.tar.gz\", \"GSM5678333_CD34-UPN11_counts.tar.gz\", \"HRI07_counts\", \"GSM5678339_...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: list_directory\n",
      "  Args: {'directory': '/Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [\"features.tsv.gz\", \"barcodes.tsv.gz\", \"matrix.mtx.gz\"]...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: get_matrix_dimensions\n",
      "  Args: {'matrix_file_path': '/Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts/matrix.mtx.gz'}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: [33538, 3152, 5203977]...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: format_features_file\n",
      "  Args: {'features_file_path': '/Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts/features.tsv.gz', 'matrix_dimensions': [33538, 3152, 5203977]}\n",
      "  Tool: format_barcodes_file\n",
      "  Args: {'barcodes_file_path': '/Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts/barcodes.tsv.gz', 'matrix_dimensions': [33538, 3152, 5203977]}\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: /Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts/barcodes.tsv.gz...\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: /Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts/features.tsv.gz...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Tool: build_anndata\n",
      "  Args: {'counts_directory': '/Users/tatarakis/data/langchain_geo_test_data/BM-Old4_counts', 'sample_name': 'BM-Old4', 'output_dir': '/Users/tatarakis/data/langchain_geo_test_data'}\n",
      "AnnData object successfully saved at: /Users/tatarakis/data/langchain_geo_test_data/adatas/BM-Old4.h5ad\n",
      "\n",
      "==================================================\n",
      "Node: tools\n",
      "==================================================\n",
      "Type: ToolMessage\n",
      "  Content: /Users/tatarakis/data/langchain_geo_test_data/adatas/BM-Old4.h5ad...\n",
      "\n",
      "==================================================\n",
      "Node: model\n",
      "==================================================\n",
      "Type: AIMessage\n",
      "  Content: Perfect! I have successfully processed the GSE188367 dataset. Here's a summary of what was accomplished:\n",
      "\n",
      "## Summary\n",
      "\n",
      "1. **Downloaded files** from GEO accession GSE188367:\n",
      "   - GSE188367_RAW.tar (containing 24 sample files)\n",
      "   - GSE188367_atac_tf_counts.tar.gz (ATAC-seq data)\n",
      "\n",
      "2. **Extracted archives**:\n",
      "   - First extracted the main RAW tar file, which contained 24 individual sample tar.gz files\n",
      "   - Then extracted all nested tar.gz files to get the individual sample count matrices\n",
      "\n",
      "3. **Found 2...\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": f\"\"\"Download counts data for assession GSE188367, keep an eye out for tar archives and extract as needed. Extract the 10x Genomics counts matrix, \n",
    "    reformat as needed, and build an AnnData object from it.\n",
    "\n",
    "    Use {WORKING_DIR} as the base directory for all file operations.\"\"\"\n",
    "        }]\n",
    "}):\n",
    "\n",
    "    # chunk is a dict with node name as key\n",
    "    for node_name, node_output in chunk.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Node: {node_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if \"messages\" in node_output:\n",
    "            for msg in node_output[\"messages\"]:\n",
    "                print(f\"Type: {type(msg).__name__}\")\n",
    "                if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                    for tc in msg.tool_calls:\n",
    "                        print(f\"  Tool: {tc['name']}\")\n",
    "                        print(f\"  Args: {tc['args']}\")\n",
    "                elif hasattr(msg, \"content\"):\n",
    "                    print(f\"  Content: {msg.content}\")\n",
    "\n",
    "\n",
    "#     \"messages\": [{\n",
    "#         \"role\": \"user\", \n",
    "#         \"content\": f\"\"\"Download counts data for each accession in {test_accessions}, keep an eye out for tar archives and extract as needed. Extract the 10x Genomics counts matrix, \n",
    "# reformat as needed, and build an AnnData object from it.\n",
    "\n",
    "# Use {WORKING_DIR} as the base directory for all file operations.\"\"\"\n",
    "#     }]\n",
    "# })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
